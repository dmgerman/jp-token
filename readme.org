* mode for reading japanese

- tokenize Japanese text
- keep track of reading status of words (similar to Anki's [[https://ankiweb.net/shared/info/900801631][morphan]] and [[https://ankiweb.net/shared/info/900801631][Migaku]])
- overlay information about the definition and pronunciation of current word
   (similar to  [[https://chrome.google.com/webstore/detail/yomichan/ogmnaimimemjmbakcfefmnahgdfhfami][yomichan]])

#+ATTR_HTML: :width 100
#+ATTR_ORG: :width 800px
[[./screenshot.png]]


* This is work in progress.

- [X] tokenize and colour tokens by type
- [-] typeset the text according to learning status (still to be completed)
  - [X] known status saved in a SQLite database
  - [-] ability to change status interactively
- [ ] display dictionary (similar to [[https://chrome.google.com/webstore/detail/yomichan/ogmnaimimemjmbakcfefmnahgdfhfami][yomichan]])
- [ ] support pitch accent
- [-] add info for N-levels (N5, N4 and N3)
- [ ] make it async
- [ ] put all together into a minor local mode
- [X] operate in regions    
- [ ] create reports of "readability"
- [ ] support for morphman and anki  
- [ ] rename everything to something more meaningful
- [ ] remove unnecessary code
- [ ] reorganize code  
- [ ] keep track of known kanji?

* Nomenclature

- a Japanese text is composed of a sequence of tokens, some of them non-japanese.
- mecab converts the input text into a sequence of tokens
- a morph (see morphman) is a Japanese word as it is learned
  - it is composed of 3 parts:
    1. surface. The version of the root known/learned
    2. root. the actual word
    3. type. the grammatical type of word
- this module keeps track of the learned status of a word:
  - ignore: we don't care for it, i.e. names, or interjections)
  - known: the surface of the word (i.e. seen version of the root, eg. たベル vs 食べる) is known
- if the morph is not in the db, it means it is unknown

* how to use

** requirements

*** mecab

This module relies primarily on mecab to parse japanese. In particular it uses mecab unidict.

You will have to have a running installation of mecab. Make sure you can run mecab. For example, make sure you get the following output
(replace /Users/dmg/bin/osx/m-mecab.sh  with the path to mecab in your installation). Note the number of columns.

#+begin_src bash :results verbatim :exports both
echo "猫が大好きです。" | /Users/dmg/bin/osx/m-mecab.sh 
#+end_src

#+RESULTS:
#+begin_example
猫	名詞,普通名詞,一般,*,*,*,ネコ,猫,猫,ネコ,猫,ネコ,和,*,*,*,*,*,*,体,ネコ,ネコ,ネコ,ネコ,1,C4,*,7918141678166528,28806
が	助詞,格助詞,*,*,*,*,ガ,が,が,ガ,が,ガ,和,*,*,*,*,*,*,格助,ガ,ガ,ガ,ガ,*,"動詞%F2@0,名詞%F1",*,2168520431510016,7889
大好き	形状詞,一般,*,*,*,*,ダイスキ,大好き,大好き,ダイスキ,大好き,ダイスキ,混,*,*,*,*,*,*,相,ダイスキ,ダイスキ,ダイスキ,ダイスキ,1,C1,*,6326873407758848,23017
です	助動詞,*,*,*,助動詞-デス,終止形-一般,デス,です,です,デス,です,デス,和,*,*,*,*,*,*,助動,デス,デス,デス,デス,*,"形容詞%F2@-1,動詞%F2@0,名詞%F2@1",*,7051468750332587,25653
。	補助記号,句点,*,*,*,*,*,。,。,*,。,*,記号,*,*,*,*,*,*,補助,*,*,*,*,*,*,*,6880571302400,25
EOS
#+end_example


*** emacs' emacsql module installed

You need to install [[https://github.com/magit/emacsql]].


** installation

- make sure mecab is installed and can be run from the command line. See above
- copy one of the status databases from [[./dbs/]] into your preferred location. The default location is ~/jp-status.db


#+begin_src emacs-lisp   :exports both
(require 'jp-token)

;; replace with your path to mecab
(setq my-command  "/Users/dmg/bin/osx/m-mecab.sh")

;; replace with your preferred name and location. If the database does not exist, it will be created.
(setq my-status-db-file "~/jp-status.db")

#+end_src

you will now have two commands available:

#+begin_src emacs-lisp   :exports both
my-do-buffer
#+end_src

this function will process the entire buffer.

and 

#+begin_src emacs-lisp   :exports both
my-do-region
#+end_src

which will do only the current region.

Both commands can be run on text that has been already processed.


* Limitations

- work in progress.
- Tested only in macos but it should work without problems in linux
- Processing of large text can take few seconds. For example Alice in Wonderland takes 8 seconds to process on an M1 mini.
 

* status database

The status database is a sqlite database created and managed by emacsql. This means that all attributes are surrounded by double quotes.

The schema is fairly simple:

| attribute | description                              |
|-----------+------------------------------------------|
| morph     | root of the morph                        |
| mtype     | type                                     |
| surface   | the root as processed                    |
| status    | one of several: known, unknown, learning |
| date      | date the tuple was added to the relation |

The primary key is (morph, mtype, surface)

there are databases with different JLPT levels at [[./dbs/]]

* dictionary

Support via an external dictionary. Most likely [[https://github.com/melissaboiko/myougiden][myougiden]]

* mecab parsing

From each sentence we obtain the root, the type of word, and the surface (kanji/hiragana version seen). For example:

#+begin_example
美味しい寿司を食べた。おいしくないすしはたべられない
#+end_example

#+name: mecab
#+begin_src bash :results verbatim :exports both
echo "美味しい寿司を食べた。おいしくないすしはたべられない" | m-mecab.sh
#+end_src

#+RESULTS:
#+begin_example
美味しい	形容詞,一般,*,*,形容詞,連体形-一般,オイシイ,美味しい,美味しい,オイシー,美味しい,オイシー,和,*,*,*,*,*,*,相,オイシイ,オイシイ,オイシイ,オイシイ,"0,3",C2,*,1201225110528705,4370
寿司	名詞,普通名詞,一般,*,*,*,スシ,寿司,寿司,スシ,寿司,スシ,和,ス濁,基本形,*,*,*,*,体,スシ,スシ,スシ,スシ,"1,2",C3,*,5269967956222464,19172
を	助詞,格助詞,*,*,*,*,ヲ,を,を,オ,を,オ,和,*,*,*,*,*,*,格助,ヲ,ヲ,ヲ,ヲ,*,"動詞%F2@0,名詞%F1,形容詞%F2@-1",*,11381878116459008,41407
食べ	動詞,一般,*,*,下一段-バ行,連用形-一般,タベル,食べる,食べ,タベ,食べる,タベル,和,*,*,*,*,*,*,用,タベ,タベル,タベ,タベル,2,C1,M4@1,6220495691326081,22630
た	助動詞,*,*,*,助動詞-タ,終止形-一般,タ,た,た,タ,た,タ,和,*,*,*,*,*,*,助動,タ,タ,タ,タ,*,"動詞%F2@1,形容詞%F4@-2",*,5948916285711019,21642
。	補助記号,句点,*,*,*,*,*,。,。,*,。,*,記号,*,*,*,*,*,*,補助,*,*,*,*,*,*,*,6880571302400,25
おいしく	形容詞,一般,*,*,形容詞,連用形-一般,オイシイ,美味しい,おいしく,オイシク,おいしい,オイシー,和,*,*,*,*,*,*,相,オイシク,オイシイ,オイシク,オイシイ,"0,3",C2,*,1201225076974209,4370
ない	形容詞,非自立可能,*,*,形容詞,連体形-一般,ナイ,無い,ない,ナイ,ない,ナイ,和,*,*,*,*,*,*,相,ナイ,ナイ,ナイ,ナイ,1,C3,*,7543208145986241,27442
すし	名詞,普通名詞,一般,*,*,*,スシ,寿司,すし,スシ,すし,スシ,和,ス濁,基本形,*,*,*,*,体,スシ,スシ,スシ,スシ,"1,2",C3,*,5269967855559168,19172
は	助詞,係助詞,*,*,*,*,ハ,は,は,ワ,は,ワ,和,*,*,*,*,*,*,係助,ハ,ハ,ハ,ハ,*,"動詞%F2@0,名詞%F1,形容詞%F2@-1",*,8059703733133824,29321
たべ	動詞,一般,*,*,下一段-バ行,未然形-一般,タベル,食べる,たべ,タベ,たべる,タベル,和,*,*,*,*,*,*,用,タベ,タベル,タベ,タベル,2,C1,M4@1,6220495657771585,22630
られ	助動詞,*,*,*,助動詞-レル,未然形-一般,ラレル,られる,られ,ラレ,られる,ラレル,和,*,*,*,*,*,*,助動,ラレ,ラレル,ラレ,ラレル,*,動詞%F3@2,M4@1,10936575907209793,39787
ない	助動詞,*,*,*,助動詞-ナイ,終止形-一般,ナイ,ない,ない,ナイ,ない,ナイ,和,*,*,*,*,*,*,助動,ナイ,ナイ,ナイ,ナイ,*,動詞%F3@0,*,7542108634358443,27438
EOS
#+end_example


This output is reduced to the following. The first column is the word as seen, the second the type, then the morph, and
finally the surface. Compare 美味しい and おいしい.

#+begin_src bash :results verbatim :exports both
echo "美味しい寿司を食べた。おいしくないすしはたべられない" | m-mecab.sh | csvcut -c 1,8,11
#+end_src

#+RESULTS:
#+begin_example
美味しい	形容詞,美味しい,美味しい
寿司	名詞,寿司,寿司
を	助詞,を,を
食べ	動詞,食べる,食べる
た	助動詞,た,た
。	補助記号,。,。
おいしく	形容詞,美味しい,おいしい
ない	形容詞,無い,ない
すし	名詞,寿司,すし
は	助詞,は,は
たべ	動詞,食べる,たべる
られ	助動詞,られる,られる
ない	助動詞,ない,ない
EOS,,
#+end_example


This text would be stored as follows in the database. Note that 寿司 and 美味しい are stored twice. One for each version (kanji and hiragana).


#+begin_src bash :results raw :exports results
echo "美味しい寿司を食べた。おいしくないすしはたべられない" | m-mecab.sh | csvcut -c 1,8,11 | csvcut -t -c 2 -u 3
#+end_src

| wtype  | root   | surface |
|--------+--------+---------|
| 助動詞  | た      | た       |
| 助動詞  | ない    | ない     |
| 助動詞  | られる  | られる   |
| 助詞    | は      | は       |
| 助詞    | を      | を       |
| 動詞    | 食べる  | たべる   |
| 動詞    | 食べる  | 食べる   |
| 名詞    | 寿司    | すし     |
| 名詞    | 寿司    | 寿司     |
| 形容詞  | 無い    | ない     |
| 形容詞  | 美味しい | おいしい  |
| 形容詞  | 美味しい | 美味しい  |

* speed

Processing large amounts of text is slow. In my tests, emacs can do Alice in Wonderland in 10-15 seconds.


- as of [2023-04-30 Sun] the profiler reports this processing Alice:
  - 25% cpu is GC,
    - 78% of memory is used in the process that runs mecab
  - 21% is matching the text to mecab output
  - 10% is processing mecab's output
  - based on the messages to the minibuffer, ~75% is spent running mecab
- 4.5k morphs (probably wrong due to breaking lines in wrong place)
- 98k characters
- mecab outputs 64k lines

All this seems to indicate that the real bottleneck is running mecab.

  


* pitch accent

to be done...

https://github.com/javdejong/nhk-pronunciation/blob/master/nhk_pronunciation.py

#+begin_src python   :exports both
    txt = e.midashigo1
    strlen = len(txt)
    acclen = len(e.ac)
    accent = "0"*(strlen-acclen) + e.ac
#+end_src
